# Implementation Workflow
# A straightforward workflow for implementing features with research and planning

[workflow]
name = "implementation"
description = "Build features, fix bugs, implement changes with research and validation"

[[phases]]
id = "research-planning"
prompt_files = ["research-planning"]
context_artifacts = ["research"]
required_artifacts = ["research-plan"]
prompt = """
## Tasks

1. Identify what needs to be researched for this request
2. List specific questions to answer
3. Identify sources (codebase, web, docs)

## Outputs

Write `research-plan.md` with:
- Questions to answer (grouped by domain)
- Sources to consult
- Research task assignments
"""
suggested_next = [
    { phase = "research", instruction = "Research plan ready — begin research" }
]

[[phases]]
id = "research"
use_tasks = true
supports_prototypes = true
supports_cache_reference = true
context_artifacts = ["research-plan", "research"]
required_artifacts = ["research"]
prompt = """
# Research Phase

Execute the research plan (injected above).

If prior research findings are injected above (from a previous iteration), build on them — add new findings without removing existing content.

## Tasks
Create research tasks to:
1. Explore the codebase to understand existing patterns and architecture
2. Identify files and components relevant to this request
3. Look for similar implementations to follow as examples
4. Note any constraints, dependencies, or potential blockers

Use prototype tasks if you need to answer questions through implementation (e.g., "Can library X work with Y?").

## Outputs
Synthesize findings into `research.md` with one section per task. Include:
- Brief overview of important findings
- Links to full reports in task directories

If this is a subsequent iteration, append new findings to the existing research.md content.
"""
suggested_next = [
    { phase = "evaluate-research", instruction = "Research complete — evaluate findings" }
]

[[phases]]
id = "evaluate-research"
max_retries = 4
prompt_files = ["evaluate-research"]
context_artifacts = ["research-plan", "research"]
suggested_next = [
    { phase = "plan", instruction = "All questions adequately answered" },
    { phase = "research-planning", instruction = "Significant gaps remain — plan additional research for unanswered questions" }
]

[[phases]]
id = "plan"
use_tasks = true
requires_user_input = true
context_artifacts = ["research"]
required_artifacts = ["implementation-plan", "verification-plan"]
prompt = """
# Plan Phase

Create a detailed implementation plan based on the research findings (injected above).

## Planning Tasks
Create tasks in this phase to:
1. Analyze findings and identify implementation approach
2. Break down the work into atomic, testable tasks
3. Identify which tasks can be parallelized
4. Consider test-first tasks if acceptance criteria are clear

## Outputs

### implementation-plan.md
- Recommended approach and rationale
- Task breakdown (descriptions, dependencies, steps)
- Parallelization strategy
- Risk assessment

### verification-plan.md
Create a verification plan based on what's available in the project:

```markdown
# Verification Plan

## Available Verification Methods
Analyze and document what verification is possible:
- Test suite? (`npm test`, `pytest`, `go test`, etc.)
- Type checking? (`tsc`, `mypy`, `pyright`, etc.)
- Linting? (`eslint`, `ruff`, etc.)
- Build verification? (`npm run build`, `make`, etc.)
- MCP tools? (browser automation, API testing, etc.)

## Automated Checks
List specific commands to run:
- [ ] `<command>` - <what it verifies>

## Interactive Verification (if MCP available)
If browser/UI MCP servers are available, list verification steps:
- [ ] Navigate to <url>, verify <expected behavior>

## Acceptance Criteria
What must be true for implementation to be complete?
```

Note: The implement phase will create its own tasks.json from the implementation plan.
"""
suggested_next = [
    { phase = "implement", instruction = "Plan approved — begin implementation" },
    { phase = "plan", instruction = "Revise the plan" },
    { phase = "research", instruction = "Return to research for additional investigation", requires_approval = true, approval_prompt = "Return to research for additional investigation?" }
]

[[phases]]
id = "implement"
use_tasks = true
max_retries = 3
context_artifacts = ["implementation-plan"]
required_json_artifacts = ["proposals", "challenges"]
prompt_files = ["implement"]
prompt = """
## Task Schema - context_artifacts

When creating tasks, use `context_artifacts` to give tasks access to relevant documents:

```json
{
  "id": "implement-auth",
  "description": "Implement authentication",
  "context_artifacts": ["request", "findings"],
  ...
}
```

**When to use context_artifacts:**
- Research/exploration tasks → `["request"]` (need the original requirements)
- Implementation tasks → `["request", "findings"]` or `["request", "design"]`
- Validation tasks → `["request"]` (to verify against requirements)

Artifacts must be recorded via `record-artifact` to be available. Common artifacts:
- `request` - Original user request
- `findings` - Exploration/research findings
- `design` - Design document (if design phase exists)

Follow existing code patterns identified during research.
"""
suggested_next = [
    { phase = "validate", instruction = "All tasks complete — run verification" },
    { phase = "implement", instruction = "Task blocked — retry with adjusted approach" },
    { phase = "plan", instruction = "Reassess plan based on implementation findings", requires_approval = true, approval_prompt = "Return to plan phase to reassess based on implementation findings?" }
]

[[phases]]
id = "validate"
prompt_files = ["validate"]
context_artifacts = ["verification-plan"]
suggested_next = [
    { phase = "complete", instruction = "All checks pass" },
    { phase = "implement", instruction = "Checks failed — fix and retry" },
    { phase = "plan", instruction = "Reassess plan based on validation findings", requires_approval = true, approval_prompt = "Return to plan phase to reassess based on validation findings?" }
]

[[phases]]
id = "complete"
prompt_files = ["proposals-and-challenges", "complete-implementation"]
terminal = true
