# Design-and-Implementation Workflow
# Design first, then optionally implement after user approval

[workflow]
name = "design-and-implementation"
description = "Design a solution, get user approval, then optionally implement"

[[phases]]
id = "research"
use_tasks = true
supports_prototypes = true
supports_cache_reference = true
max_iterations = 4
required_artifacts = ["research"]
prompt = """
# Research Phase

Investigate the problem space before designing.

## Tasks
1. Explore the existing codebase
2. Research potential approaches
3. Identify constraints and requirements
4. Document trade-offs
5. **Assess verification capabilities** (see below)

## Verification-Aware Research

Before finalizing your research, understand what verification is possible:

### Discover Available Tools
- What test frameworks exist? (`package.json`, `pytest.ini`, `go.mod`, etc.)
- What MCP servers are available? (browser automation, API testing, etc.)
- What build/lint/type-check commands exist?

### Influence Design Choices
**Prefer approaches that can be self-verified.** When comparing options:
- Favor technologies with existing test patterns in the codebase
- Prefer architectures that work with available MCP tools
- Consider: "How will I verify this actually works?"

### Document in research.md
Include a section:
```markdown
## Verification Capabilities

### Available Tools
- Test suite: `npm test` (Jest)
- Type checking: `tsc --noEmit`
- MCP: Browser automation available via playwright MCP

### Verification Considerations
- [How each approach option can be verified]
- [Which option is easiest to verify]
```

## Outputs
Write `research.md` with findings, including verification capabilities.

Use prototype tasks if you need to answer questions through implementation.
"""
suggested_next = ["research", "draft"]

[[phases]]
id = "draft"
required_artifacts = ["design", "verification-plan"]
prompt = """
# Draft Phase

Create the design document.

## Inputs
Review research.md from research phase, including verification capabilities.

## Tasks
1. Synthesize research into a design
2. Document the proposed solution
3. Include implementation plan preview
4. **Create verification plan** (see below)

## Outputs

### design.md
Write the complete design document.

### verification-plan.md
Based on the verification capabilities identified in research, create a concrete plan:

```markdown
# Verification Plan

## Automated Checks
Commands to run after implementation:
- [ ] `<test command>` - <what it verifies>
- [ ] `<type check command>` - <what it verifies>
- [ ] `<lint command>` - <what it verifies>
- [ ] `<build command>` - <what it verifies>

## Interactive Verification
If MCP tools are available (browser, API, etc.):
- [ ] <step> - <expected result>
- [ ] <step> - <expected result>

## Acceptance Criteria
Specific criteria that must be true:
- [ ] <criterion derived from requirements>
- [ ] <criterion derived from design>
```
"""
suggested_next = ["review"]

[[phases]]
id = "review"
use_tasks = true
prompt = """
# Review Phase

Get external feedback on the design using reviewer agents.

## Setup

Create tasks.json with reviewer tasks. Reviewer tasks can run in parallel since they have no dependencies on each other.

### Example tasks.json

```json
[
  {
    "id": "gemini-review",
    "description": "Get design feedback from Gemini",
    "subagent": "gemini-reviewer",
    "subagent_prompt": "Review the design for architectural concerns, completeness, and clarity",
    "context_artifacts": ["design", "verification-plan"],
    "parents": [],
    "status": "todo"
  },
  {
    "id": "codex-review",
    "description": "Get design feedback from Codex",
    "subagent": "codex-reviewer",
    "subagent_prompt": "Review the design for technical accuracy and implementation feasibility",
    "context_artifacts": ["design", "verification-plan"],
    "parents": [],
    "status": "todo"
  },
  {
    "id": "synthesize-feedback",
    "description": "Synthesize feedback into review-feedback.md",
    "parents": ["gemini-review", "codex-review"],
    "steps": [
      "Read output from parent tasks",
      "Categorize feedback: critical, suggestion, nit",
      "Write review-feedback.md"
    ],
    "status": "todo"
  }
]
```

## Task Execution

1. Run reviewer tasks in parallel (they have no parents)
2. After both complete, run synthesize task
3. Mark each task done as it completes

## Outputs

Write `review-feedback.md` with categorized feedback from all reviewers.
"""
suggested_next = ["revise"]

[[phases]]
id = "revise"
prompt = """
# Revise Phase

Incorporate feedback and finalize design.

## Inputs
- design.md from previous draft/revise
- review-feedback.md from external reviewers
- User guidance (if re-entering from user-decision)

## Check for User Guidance

If the user provided feedback when selecting revise, retrieve it:
```bash
uv run ~/.claude-plugins/jons-plan/plan.py get-user-guidance
```

Address their specific concerns in the revision. After processing, clear it:
```bash
uv run ~/.claude-plugins/jons-plan/plan.py clear-user-guidance
```

## Tasks
1. Read user guidance if present
2. Address feedback in design.md (focus on user's concerns)
3. Update confidence assessment

## Outputs
Updated design.md ready for user review.
"""
suggested_next = ["user-decision"]

[[phases]]
id = "user-decision"
prompt = """
# User Decision Phase

Present the design to the user for approval.

## User Review
The user should review:
- design.md - The proposed solution
- review-feedback.md - External feedback received
"""
requires_user_input = true
user_review_artifacts = ["design.md", "review-feedback.md"]
suggested_next = ["implement", "complete-design-only", "revise"]

[[phases]]
id = "implement"
use_tasks = true
supports_proposals = true
on_blocked = "self"
max_retries = 3
prompt = """
# Implement Phase

Execute the design.

## Inputs
- design.md with approved design
- research.md for context

## Setup
1. Create tasks.json with implementation plan based on design.md
2. All tasks start with `status: "todo"`

Note: verification-plan.md was created in the draft phase and is available as an artifact.

## Task Schema - context_artifacts

When creating tasks, use `context_artifacts` to give tasks access to relevant documents:

```json
{
  "id": "implement-feature",
  "description": "Implement the feature",
  "context_artifacts": ["request", "design"],
  ...
}
```

**When to use context_artifacts:**
- Implementation tasks → `["request", "design"]` (need requirements + design)
- Validation tasks → `["request", "design"]` (to verify against both)

Common artifacts in this workflow:
- `request` - Original user request
- `research` - Research findings
- `design` - Approved design document

## Task Execution
1. Execute tasks following the design
2. Set each task to in-progress before starting
3. Mark tasks done immediately after completion

## Outputs
Working implementation of the design.
"""
suggested_next = [
    "validate",
    { phase = "research", requires_approval = true, approval_prompt = "Return to research phase for additional investigation?" }
]

[[phases]]
id = "validate"
prompt = """
# Validate Phase

Verify implementation matches the design using the verification plan.

## Inputs
The verification-plan artifact contains the checks to run.

## Execution

### 1. Run Automated Checks
Execute each command from the verification plan:
- Run test suite
- Run type checker
- Run linter
- Run build

Log results for each check.

### 2. Interactive Verification (if applicable)
If the verification plan includes MCP-based checks:
- Execute browser automation steps
- Verify UI behavior matches design

### 3. Acceptance Criteria
Verify each criterion from the verification plan (derived from design.md) is met.

## Outcomes

**All checks pass:** Transition to complete.

**Checks fail:**
- If fixable: Fix and re-run checks
- If needs rework: Transition back to implement
"""
suggested_next = [
    "complete",
    { phase = "research", requires_approval = true, approval_prompt = "Return to research phase for additional investigation?" }
]
on_blocked = "implement"

[[phases]]
id = "complete"
prompt = """
# Complete Phase

Finalize the implementation.

## Review CLAUDE.md Proposals

If implementation generated any CLAUDE.md improvement proposals:

1. Collect proposals:
   ```bash
   uv run ~/.claude-plugins/jons-plan/plan.py collect-proposals
   ```

2. List pending proposals:
   ```bash
   uv run ~/.claude-plugins/jons-plan/plan.py list-proposals
   ```

3. For each pending proposal, present to user via AskUserQuestion:
   - Show: target file, proposed content, rationale
   - Options: Accept, Reject
   - If Accept: use Edit tool to apply the change to the target file
   - Update status: `uv run ~/.claude-plugins/jons-plan/plan.py update-proposal-status <id> accepted|rejected`

## Final Tasks
1. Review all changes
2. Prepare commit message
3. Document any follow-up work

This is a terminal phase.
"""
terminal = true

[[phases]]
id = "complete-design-only"
prompt = """
# Complete Design Only

Finalize without implementation.

The design document is complete. Implementation can be done
separately using the `/jons-plan:new` command with this design
as reference.

This is a terminal phase.
"""
terminal = true
